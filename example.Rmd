---
author: "Sean Anderson, Paul Regular"
title: "Example of simulating data with SimSurvey and index standardization with sdmTMB"
---

# Setup

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
theme_set(theme_minimal())
library(SimSurvey)
library(sdmTMB)
```

# Population and survey simulation

First we will simulate a spatial, age-structured population with SimSurvey. In short, here is what is going on in the following chunk:

-   `sim_abundance()` is using a cohort equation to simulate an age-structured population including ages 1 to 20 [`ages = seq(1, 20)`], across 10 years [`years = seq(1, 10)`]

-   `sim_distribution()` is distributing the age-structured population from `sim_abundance()` over space. Specifically it

    -   spreads the population over a square grid [`make_grid()`] with a cell resolution of 10 x 10 km [`res = c(10, 10)`] and depths between 10 to 500 m [`depth_range = c(10, 500))`];

    -   adds noise correlated across space, year, and age dimensions [`sim_ays_covar()`], with strong correlation across ages [`phi_age = 0.8`] but weak correlation across years [`phi_year = 0.1`]; and

    -   adds a parabolic depth 'preference' [`sim_parabola()`] where there is a propensity for fish to occur around 200 meters [`mu = 200, sigma = 30`].

There are several arguments not modified in the example below. As such, defaults are largely used and these settings were based on a cod stock off the south coast of Newfoundland (3Ps cod). So, consider this a simulation for a cod-like species.

```{r}
set.seed(42)
sim <- SimSurvey::sim_abundance(ages = seq(1, 20), years = seq(1, 10)) %>%
  SimSurvey::sim_distribution(
    grid = SimSurvey::make_grid(res = c(10, 10), depth_range = c(10, 500)),
    ays_covar = SimSurvey::sim_ays_covar(phi_age = 0.8, phi_year = 0.1),
    depth_par = SimSurvey::sim_parabola(mu = 200, sigma = 30)
  )
```

Several matrices and tables are generated by these functions. We will extract some key tables for some plotting below:

```{r}
xy_sim <- as_tibble(sim$grid_xy)
df_sim <- as_tibble(sim$sp_N)
df_sim <- left_join(df_sim, xy_sim, by = "cell")
```

Next we will conduct a survey on our simulated population using the `sim_survey()` function. By default, this function applies stratified random sampling of a survey with a catchability defined using a logistic curve [`sim_logistic()`]. We will work with a single replicate for simplicity. We will also add results from a stratified analysis to the output [`run_strat()`] for later comparisons to model-based estimates.

```{r}
survey <- SimSurvey::sim_survey(sim, q = sim_logistic(), n_sims = 1) %>% 
  SimSurvey::run_strat()
```

And, again, we can extract some key tables that will be used to analyze and plot the simulated data:

```{r}
xy <- tibble::as_tibble(survey$grid_xy)
dat <- tibble::as_tibble(survey$setdet) %>% select(x, y, set, year, N = n, tow_area)
dat <- left_join(dat, xy, by = c("x", "y"))
```

Here are the survey observations:

```{r}
ggplot(dat, aes(x, y, colour = log(N + 1), size = N)) +
  geom_point() +
  facet_wrap(vars(year)) +
  scale_colour_viridis_c() +
  scale_size_area(max_size = 4)
```

This is what the data look like:

```{r}
glimpse(dat)
```

And the underlying abundance:

```{r}
df_sim %>% 
  group_by(x, y, year, cell) %>% 
  summarise(N = sum(N), .groups = "drop") %>% 
  ggplot(aes(x, y, fill = log(N + 1))) +
  geom_raster() +
  facet_wrap(~year) +
  scale_fill_viridis_c()
```

# Fitting a geostatistical spatiotemporal model

First, we need to set up an SPDE (Stochastic partial differential equation) mesh object via the INLA R package. The important part of this is coming up with a reasonable resolution of "knots" or representative locations that will be modelled. Values in between these knots will be interpolated with bilinear interpolation along the triangles. This approach greatly increases computational efficiency.

```{r}
mesh <- sdmTMB::make_mesh(dat, xy_cols = c("x", "y"), cutoff = 15)
```

We can make a plot of our mesh:

```{r}
plot(mesh)
```

And look at how many knots there are. Smaller `cutoff` values (in units x-y coordinate units), will generate more knots. More knots will make for a better approximation at the expense of fitting time. There are other possible meshes and you can use any mesh from INLA.

```{r}
mesh$mesh$n
```

We will set up an "offset" variable to represent the tow area. Details [here](https://stats.stackexchange.com/questions/11182/when-to-use-an-offset-in-a-poisson-regression) and [here](https://stats.stackexchange.com/questions/66791/where-does-the-offset-go-in-poisson-negative-binomial-regression?noredirect=1&lq=1).

Here the tow area is the same on all sets, but this wouldn't necessarily be the case. Alternatively, continuous biomass density data with zeros could be modelled with the Tweedie distribution and a log link. Because this example works with counts of fish, we will use a negative binomial family.

```{r}
dat$offset <- log(dat$tow_area)
```

Next we will fit the model. In the following code chunk:

-   `include_spatial = TRUE` means the model will include a separate spatial random field (a wiggly intercept surface that stays constant through time) and spatiotemporal fields (a random field that varies each year). There's also an option for correlated fields (`ar1_fields = TRUE`).
-   `time = "year"` tells the function which column of data represents the time element and tells the model this is spatiotemporal, not just spatial, data.
-   `silent = FALSE` tells the function to print out TMB progress messages.
-   `offset` is a reserved word in sdmTMB and will be fit with its coefficient fixed at 1.
-   `0 + as.factor(year)` in the formula sets up the model matrix so that there is an independent mean for each year.
-   `spde = mesh` tells it to use our mesh from above.

```{r fit, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
fit <- sdmTMB(N ~ 0 + as.factor(year) + offset,
              data = dat,
              family = nbinom2(link = "log"), spde = mesh,
              include_spatial = TRUE,
              time = "year",
              silent = FALSE
)
```

We can look at a summary of our fit:

```{r}
print(fit)
```

And extract values from estimated fixed and random effect variables using the `tidy()` method, which follows the broom package convention:

```{r}
tidy(fit, conf.int = TRUE)
tidy(fit, conf.int = TRUE, effects = "ran_pars")
```

We can look at residuals:

```{r}
dat$resid <- residuals(fit)

ggplot(dat, aes(x, y, colour = resid, size = abs(resid))) +
  geom_point() +
  facet_wrap(~year) +
  scale_colour_gradient2() +
  scale_size_area(max_size = 2)
```

These are randomized quantile residuals---similar to the DHARMa R package. These are adjusted so that they would be Gaussian distributed if the model were consistent with the data:

```{r}
hist(dat$resid)
```

# Predicting over the survey domain and calculating an index of abundance

To calculate an index of abundance, first we need to create a grid that covers the entirety of our survey domain. In this case that would be a square grid:

```{r}
grid_dat <- tidyr::expand_grid(x = sort(unique(df_sim$x)), y = sort(unique(df_sim$y)))
grid_dat <- purrr::map_dfr(sort(unique(dat$year)), ~ bind_cols(grid_dat, year = .))
grid_dat$offset <- mean(dat$offset)
```

Next we need to predict from our model onto our survey grid. `return_tmb_object = TRUE` tells the function to return a TMB object that is critical for calculating the survey index. If enabled, the result will be a list with the predictions as one element and the TMB object as another. If disabled, the result will just be a prediction data frame.

The `area` argument represents the area of a grid cell so that the resulting estimate is per m^2^ or km^2^. Here, that is 10 x 10 km. `area` can be a vector if some grid cells overlap land or are partially outside the survey domain.

```{r}
pred <- predict(fit, newdata = grid_dat, return_tmb_object = TRUE, area = 100)
```

These are the prediction elements. See `?predict.sdmTMB` for details.

```{r}
head(pred$data)
```

We can stop to plot the predicted and true known abundance distribution through time. Note that the true abundance row does not account for survey catchability or selectivity in this plot. Here, we have scaled them by their geometric means.

```{r}
true <- df_sim %>% 
  group_by(x, y, year, cell) %>% 
  summarise(N = sum(N), .groups = "drop")  %>%
  select(x, y, year, N) %>%
  mutate(type = "True")
fitted <- pred$data %>%
  select(x, y, year, est) %>%
  mutate(type = "Predicted") %>%
  mutate(N = exp(est))
both <- bind_rows(true, fitted) %>%
  group_by(type) %>%
  mutate(N_scaled = N / exp(mean(log(N))))
ggplot(both, aes(x, y, fill = log(N_scaled))) +
  geom_tile() +
  facet_grid(type ~ year) +
  scale_fill_viridis_c(limits = quantile(log(both$N_scaled), probs = c(0.05, 1)))
```

```{r}
filter(both, year %in% 1:5) %>% 
  ggplot(aes(x, y, fill = log(N_scaled))) +
  geom_raster() +
  facet_grid(type ~ year) +
  scale_fill_viridis_c(limits = quantile(log(both$N_scaled), probs = c(0.05, 1)))
```

We can pass the output from our prediction into the `get_index()` function. It sums up the abundance in all of the grid cells and calculates standard errors on the result.

There is an option to enable bias correction (`bias_correct = TRUE`) because of the [non-linear transformation](https://www.sciencedirect.com/science/article/abs/pii/S0165783615301399) of the random effects (exp). This will not have a noticeable difference here because the sampling is relatively constant across space and years, but in some situations it would be important to turn on. It would be much slower, so we will not work with that here.

```{r}
index <- get_index(pred)
```

Now we can combine our estimated index with the "true" known population trajectory, which does account for selectivity (but not catchability):

```{r}
true_abund <- tibble(year = unique(df_sim$year), N = as.numeric(colSums(survey$I))) %>%
  mutate(type = "True")
strat_abund <- tibble::as_tibble(survey$total_strat) %>% 
  mutate(N = total, type = "Design-based") %>% 
  select(year, N, type)
both <- index %>%
  mutate(type = "Model-based", N = est) %>%
  bind_rows(true_abund) %>%
  bind_rows(strat_abund) %>% 
  group_by(type) %>%
  mutate(geo_mean = exp(mean(log(N), na.rm = TRUE)),
         lwr_scaled = lwr / geo_mean, N_scaled = N / geo_mean, upr_scaled = upr / geo_mean,
         type = factor(type, levels = c("True", "Design-based", "Model-based"))) %>% 
  arrange(type)
```

And make a plot of the result:

```{r, warning=FALSE}
ggplot(both, aes(year, N_scaled, group = type)) +
  geom_line(aes(colour = type, size = type)) +
  geom_ribbon(aes(ymin = lwr_scaled, ymax = upr_scaled, fill = type), alpha = 0.3) +
  labs(x = "Year", y = "Relative abundance", colour = "Type", fill = "Type", size = "Type") +
  scale_color_manual(values = c("Model-based" = "grey30", "Design-based" = "steelblue", "True" = "red")) +
  scale_fill_manual(values = c("Model-based" = "grey30", "Design-based" = "steelblue", "True" = "red")) +
  scale_size_manual(values = c("Model-based" = 0.5, "Design-based" = 0.5, "True" = 1))
```

# Questions / potential next steps

-   [ ] Does including a covariate - e.g., spline(depth) - increase precision, estimate the right depth relationship, and maintain an unbiased index with greater precision (compared to not including any covariates)? Are there scenarios where that is or isn't the case?

-   [ ] If we throw out a spatial rectangle of the survey - e.g. multiple strata, half the survey area - in some years, can the model recover the index?

-   [ ] Does using an AR1 spatiotemporal field (without factor levels for years) constrain the model too much and result in hyperstability?

-   [ ] If the catchability of a survey changed along the time series, say the gear was changed and there was one year of calibration overlap, could the model estimate the q offset and provide unbiased estimates of the population available to the contemporary survey as if those gear were used the whole time?

-   [ ] If two surveys with different catchabilities are conducted in parallel at neighboring divisions, could a model 'stitch' these surveys together to provide a unified estimate of the population?

-   [ ] Are there survey designs that result in the model-based index being more or less precise than the design based index?

-   [ ] Can we obtain an index at age using a geostatistical model?
